{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation , Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "directory_path = '/content/drive/MyDrive/LS2024/ML/WEEK2/homer_bart'\n",
        "\n",
        "def load_and_preprocess_images(directory, target_size=(64, 64)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_map = {'Homer': 0, 'Bart': 1}\n",
        "\n",
        "    for label_name in ['Homer', 'Bart']:\n",
        "        folder_path = os.path.join(directory, label_name)\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith('.bmp'):\n",
        "                img = Image.open(os.path.join(folder_path, filename))\n",
        "                img = img.resize(target_size)\n",
        "                img = np.array(img) / 255.0  #Normalized pixel values\n",
        "                images.append(img)\n",
        "                labels.append(label_map[label_name])\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "#above this was the function to preprocess the data\n",
        "images, labels = load_and_preprocess_images(directory_path)\n",
        "\n",
        "#Flattening images for Dense layer input\n",
        "images = images.reshape(images.shape[0], 64 * 64 * 3)  # Assuming RGB images\n",
        "\n",
        "#Splitting data into test and train , i got good accurracy at test_size=0.05\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.05, random_state=20)\n",
        "\n",
        "#Neural Network\n",
        "model = Sequential()\n",
        "model.add(Dense(units=128, input_dim=64*64*3, activation='relu'))\n",
        "# Dropout layer to prevent overfitting\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=100 , verbose=2  )\n",
        "\n",
        "# running the model on test data\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EnQQzm1rT5q",
        "outputId": "0d195f11-a574-4971-9f78-4fac859a0611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 - 2s - loss: 4.8436 - accuracy: 0.4784 - 2s/epoch - 240ms/step\n",
            "Epoch 2/100\n",
            "8/8 - 0s - loss: 3.9189 - accuracy: 0.4510 - 262ms/epoch - 33ms/step\n",
            "Epoch 3/100\n",
            "8/8 - 0s - loss: 1.5921 - accuracy: 0.5137 - 239ms/epoch - 30ms/step\n",
            "Epoch 4/100\n",
            "8/8 - 0s - loss: 0.7065 - accuracy: 0.5412 - 241ms/epoch - 30ms/step\n",
            "Epoch 5/100\n",
            "8/8 - 0s - loss: 0.6889 - accuracy: 0.5922 - 241ms/epoch - 30ms/step\n",
            "Epoch 6/100\n",
            "8/8 - 0s - loss: 0.6908 - accuracy: 0.5804 - 253ms/epoch - 32ms/step\n",
            "Epoch 7/100\n",
            "8/8 - 0s - loss: 0.6906 - accuracy: 0.5804 - 232ms/epoch - 29ms/step\n",
            "Epoch 8/100\n",
            "8/8 - 0s - loss: 0.6892 - accuracy: 0.5804 - 225ms/epoch - 28ms/step\n",
            "Epoch 9/100\n",
            "8/8 - 0s - loss: 0.7056 - accuracy: 0.5765 - 238ms/epoch - 30ms/step\n",
            "Epoch 10/100\n",
            "8/8 - 0s - loss: 0.6879 - accuracy: 0.5804 - 256ms/epoch - 32ms/step\n",
            "Epoch 11/100\n",
            "8/8 - 0s - loss: 0.6876 - accuracy: 0.5804 - 230ms/epoch - 29ms/step\n",
            "Epoch 12/100\n",
            "8/8 - 0s - loss: 0.6872 - accuracy: 0.5804 - 230ms/epoch - 29ms/step\n",
            "Epoch 13/100\n",
            "8/8 - 0s - loss: 0.6858 - accuracy: 0.5804 - 237ms/epoch - 30ms/step\n",
            "Epoch 14/100\n",
            "8/8 - 0s - loss: 0.6860 - accuracy: 0.5804 - 245ms/epoch - 31ms/step\n",
            "Epoch 15/100\n",
            "8/8 - 0s - loss: 0.6852 - accuracy: 0.5804 - 168ms/epoch - 21ms/step\n",
            "Epoch 16/100\n",
            "8/8 - 0s - loss: 0.6846 - accuracy: 0.5804 - 162ms/epoch - 20ms/step\n",
            "Epoch 17/100\n",
            "8/8 - 0s - loss: 0.6835 - accuracy: 0.5804 - 162ms/epoch - 20ms/step\n",
            "Epoch 18/100\n",
            "8/8 - 0s - loss: 0.6834 - accuracy: 0.5804 - 158ms/epoch - 20ms/step\n",
            "Epoch 19/100\n",
            "8/8 - 0s - loss: 0.6853 - accuracy: 0.5804 - 169ms/epoch - 21ms/step\n",
            "Epoch 20/100\n",
            "8/8 - 0s - loss: 0.6839 - accuracy: 0.5804 - 178ms/epoch - 22ms/step\n",
            "Epoch 21/100\n",
            "8/8 - 0s - loss: 0.6819 - accuracy: 0.5804 - 159ms/epoch - 20ms/step\n",
            "Epoch 22/100\n",
            "8/8 - 0s - loss: 0.6812 - accuracy: 0.5804 - 159ms/epoch - 20ms/step\n",
            "Epoch 23/100\n",
            "8/8 - 0s - loss: 0.6813 - accuracy: 0.5804 - 157ms/epoch - 20ms/step\n",
            "Epoch 24/100\n",
            "8/8 - 0s - loss: 0.6829 - accuracy: 0.5804 - 163ms/epoch - 20ms/step\n",
            "Epoch 25/100\n",
            "8/8 - 0s - loss: 0.6848 - accuracy: 0.5804 - 160ms/epoch - 20ms/step\n",
            "Epoch 26/100\n",
            "8/8 - 0s - loss: 0.6804 - accuracy: 0.5804 - 187ms/epoch - 23ms/step\n",
            "Epoch 27/100\n",
            "8/8 - 0s - loss: 0.6833 - accuracy: 0.5804 - 164ms/epoch - 21ms/step\n",
            "Epoch 28/100\n",
            "8/8 - 0s - loss: 0.6841 - accuracy: 0.5804 - 159ms/epoch - 20ms/step\n",
            "Epoch 29/100\n",
            "8/8 - 0s - loss: 0.6818 - accuracy: 0.5804 - 165ms/epoch - 21ms/step\n",
            "Epoch 30/100\n",
            "8/8 - 0s - loss: 0.6814 - accuracy: 0.5804 - 163ms/epoch - 20ms/step\n",
            "Epoch 31/100\n",
            "8/8 - 0s - loss: 0.6821 - accuracy: 0.5804 - 169ms/epoch - 21ms/step\n",
            "Epoch 32/100\n",
            "8/8 - 0s - loss: 0.6770 - accuracy: 0.5804 - 197ms/epoch - 25ms/step\n",
            "Epoch 33/100\n",
            "8/8 - 0s - loss: 0.6820 - accuracy: 0.5804 - 161ms/epoch - 20ms/step\n",
            "Epoch 34/100\n",
            "8/8 - 0s - loss: 0.6800 - accuracy: 0.5804 - 165ms/epoch - 21ms/step\n",
            "Epoch 35/100\n",
            "8/8 - 0s - loss: 0.6805 - accuracy: 0.5804 - 168ms/epoch - 21ms/step\n",
            "Epoch 36/100\n",
            "8/8 - 0s - loss: 0.6809 - accuracy: 0.5804 - 159ms/epoch - 20ms/step\n",
            "Epoch 37/100\n",
            "8/8 - 0s - loss: 0.6794 - accuracy: 0.5804 - 170ms/epoch - 21ms/step\n",
            "Epoch 38/100\n",
            "8/8 - 0s - loss: 0.6819 - accuracy: 0.5804 - 187ms/epoch - 23ms/step\n",
            "Epoch 39/100\n",
            "8/8 - 0s - loss: 0.6827 - accuracy: 0.5804 - 160ms/epoch - 20ms/step\n",
            "Epoch 40/100\n",
            "8/8 - 0s - loss: 0.6809 - accuracy: 0.5804 - 160ms/epoch - 20ms/step\n",
            "Epoch 41/100\n",
            "8/8 - 0s - loss: 0.6799 - accuracy: 0.5804 - 157ms/epoch - 20ms/step\n",
            "Epoch 42/100\n",
            "8/8 - 0s - loss: 0.6802 - accuracy: 0.5804 - 160ms/epoch - 20ms/step\n",
            "Epoch 43/100\n",
            "8/8 - 0s - loss: 0.6791 - accuracy: 0.5804 - 160ms/epoch - 20ms/step\n",
            "Epoch 44/100\n",
            "8/8 - 0s - loss: 0.6801 - accuracy: 0.5804 - 187ms/epoch - 23ms/step\n",
            "Epoch 45/100\n",
            "8/8 - 0s - loss: 0.6800 - accuracy: 0.5804 - 163ms/epoch - 20ms/step\n",
            "Epoch 46/100\n",
            "8/8 - 0s - loss: 0.6770 - accuracy: 0.5804 - 162ms/epoch - 20ms/step\n",
            "Epoch 47/100\n",
            "8/8 - 0s - loss: 0.6841 - accuracy: 0.5804 - 162ms/epoch - 20ms/step\n",
            "Epoch 48/100\n",
            "8/8 - 0s - loss: 0.6789 - accuracy: 0.5804 - 161ms/epoch - 20ms/step\n",
            "Epoch 49/100\n",
            "8/8 - 0s - loss: 0.6802 - accuracy: 0.5804 - 169ms/epoch - 21ms/step\n",
            "Epoch 50/100\n",
            "8/8 - 0s - loss: 0.6805 - accuracy: 0.5804 - 182ms/epoch - 23ms/step\n",
            "Epoch 51/100\n",
            "8/8 - 0s - loss: 0.6804 - accuracy: 0.5804 - 160ms/epoch - 20ms/step\n",
            "Epoch 52/100\n",
            "8/8 - 0s - loss: 0.6850 - accuracy: 0.5804 - 161ms/epoch - 20ms/step\n",
            "Epoch 53/100\n",
            "8/8 - 0s - loss: 0.6806 - accuracy: 0.5804 - 155ms/epoch - 19ms/step\n",
            "Epoch 54/100\n",
            "8/8 - 0s - loss: 0.6800 - accuracy: 0.5804 - 190ms/epoch - 24ms/step\n",
            "Epoch 55/100\n",
            "8/8 - 0s - loss: 0.6778 - accuracy: 0.5804 - 186ms/epoch - 23ms/step\n",
            "Epoch 56/100\n",
            "8/8 - 0s - loss: 0.6806 - accuracy: 0.5804 - 177ms/epoch - 22ms/step\n",
            "Epoch 57/100\n",
            "8/8 - 0s - loss: 0.6796 - accuracy: 0.5804 - 169ms/epoch - 21ms/step\n",
            "Epoch 58/100\n",
            "8/8 - 0s - loss: 0.6801 - accuracy: 0.5804 - 168ms/epoch - 21ms/step\n",
            "Epoch 59/100\n",
            "8/8 - 0s - loss: 0.6775 - accuracy: 0.5804 - 160ms/epoch - 20ms/step\n",
            "Epoch 60/100\n",
            "8/8 - 0s - loss: 0.6808 - accuracy: 0.5804 - 164ms/epoch - 21ms/step\n",
            "Epoch 61/100\n",
            "8/8 - 0s - loss: 0.6799 - accuracy: 0.5804 - 183ms/epoch - 23ms/step\n",
            "Epoch 62/100\n",
            "8/8 - 0s - loss: 0.6827 - accuracy: 0.5804 - 181ms/epoch - 23ms/step\n",
            "Epoch 63/100\n",
            "8/8 - 0s - loss: 0.6833 - accuracy: 0.5804 - 162ms/epoch - 20ms/step\n",
            "Epoch 64/100\n",
            "8/8 - 0s - loss: 0.6819 - accuracy: 0.5804 - 160ms/epoch - 20ms/step\n",
            "Epoch 65/100\n",
            "8/8 - 0s - loss: 0.6781 - accuracy: 0.5804 - 164ms/epoch - 20ms/step\n",
            "Epoch 66/100\n",
            "8/8 - 0s - loss: 0.6814 - accuracy: 0.5804 - 168ms/epoch - 21ms/step\n",
            "Epoch 67/100\n",
            "8/8 - 0s - loss: 0.6798 - accuracy: 0.5804 - 177ms/epoch - 22ms/step\n",
            "Epoch 68/100\n",
            "8/8 - 0s - loss: 0.6839 - accuracy: 0.5804 - 173ms/epoch - 22ms/step\n",
            "Epoch 69/100\n",
            "8/8 - 0s - loss: 0.6787 - accuracy: 0.5804 - 167ms/epoch - 21ms/step\n",
            "Epoch 70/100\n",
            "8/8 - 0s - loss: 0.6794 - accuracy: 0.5804 - 171ms/epoch - 21ms/step\n",
            "Epoch 71/100\n",
            "8/8 - 0s - loss: 0.6781 - accuracy: 0.5804 - 175ms/epoch - 22ms/step\n",
            "Epoch 72/100\n",
            "8/8 - 0s - loss: 0.6821 - accuracy: 0.5804 - 205ms/epoch - 26ms/step\n",
            "Epoch 73/100\n",
            "8/8 - 0s - loss: 0.6820 - accuracy: 0.5804 - 242ms/epoch - 30ms/step\n",
            "Epoch 74/100\n",
            "8/8 - 0s - loss: 0.6847 - accuracy: 0.5804 - 245ms/epoch - 31ms/step\n",
            "Epoch 75/100\n",
            "8/8 - 0s - loss: 0.6796 - accuracy: 0.5804 - 230ms/epoch - 29ms/step\n",
            "Epoch 76/100\n",
            "8/8 - 0s - loss: 0.6816 - accuracy: 0.5804 - 254ms/epoch - 32ms/step\n",
            "Epoch 77/100\n",
            "8/8 - 0s - loss: 0.6814 - accuracy: 0.5804 - 236ms/epoch - 30ms/step\n",
            "Epoch 78/100\n",
            "8/8 - 0s - loss: 0.6837 - accuracy: 0.5804 - 230ms/epoch - 29ms/step\n",
            "Epoch 79/100\n",
            "8/8 - 0s - loss: 0.6834 - accuracy: 0.5804 - 241ms/epoch - 30ms/step\n",
            "Epoch 80/100\n",
            "8/8 - 0s - loss: 0.6779 - accuracy: 0.5804 - 231ms/epoch - 29ms/step\n",
            "Epoch 81/100\n",
            "8/8 - 0s - loss: 0.6799 - accuracy: 0.5804 - 248ms/epoch - 31ms/step\n",
            "Epoch 82/100\n",
            "8/8 - 0s - loss: 0.6826 - accuracy: 0.5804 - 239ms/epoch - 30ms/step\n",
            "Epoch 83/100\n",
            "8/8 - 0s - loss: 0.6778 - accuracy: 0.5804 - 233ms/epoch - 29ms/step\n",
            "Epoch 84/100\n",
            "8/8 - 0s - loss: 0.6778 - accuracy: 0.5804 - 228ms/epoch - 29ms/step\n",
            "Epoch 85/100\n",
            "8/8 - 0s - loss: 0.6807 - accuracy: 0.5804 - 238ms/epoch - 30ms/step\n",
            "Epoch 86/100\n",
            "8/8 - 0s - loss: 0.6802 - accuracy: 0.5804 - 231ms/epoch - 29ms/step\n",
            "Epoch 87/100\n",
            "8/8 - 0s - loss: 0.6828 - accuracy: 0.5804 - 231ms/epoch - 29ms/step\n",
            "Epoch 88/100\n",
            "8/8 - 0s - loss: 0.6820 - accuracy: 0.5804 - 240ms/epoch - 30ms/step\n",
            "Epoch 89/100\n",
            "8/8 - 0s - loss: 0.6769 - accuracy: 0.5804 - 239ms/epoch - 30ms/step\n",
            "Epoch 90/100\n",
            "8/8 - 0s - loss: 0.6793 - accuracy: 0.5804 - 240ms/epoch - 30ms/step\n",
            "Epoch 91/100\n",
            "8/8 - 0s - loss: 0.6814 - accuracy: 0.5804 - 235ms/epoch - 29ms/step\n",
            "Epoch 92/100\n",
            "8/8 - 0s - loss: 0.6856 - accuracy: 0.5804 - 233ms/epoch - 29ms/step\n",
            "Epoch 93/100\n",
            "8/8 - 0s - loss: 0.6797 - accuracy: 0.5804 - 238ms/epoch - 30ms/step\n",
            "Epoch 94/100\n",
            "8/8 - 0s - loss: 0.6767 - accuracy: 0.5804 - 236ms/epoch - 29ms/step\n",
            "Epoch 95/100\n",
            "8/8 - 0s - loss: 0.6833 - accuracy: 0.5804 - 241ms/epoch - 30ms/step\n",
            "Epoch 96/100\n",
            "8/8 - 0s - loss: 0.6807 - accuracy: 0.5804 - 228ms/epoch - 29ms/step\n",
            "Epoch 97/100\n",
            "8/8 - 0s - loss: 0.6818 - accuracy: 0.5804 - 171ms/epoch - 21ms/step\n",
            "Epoch 98/100\n",
            "8/8 - 0s - loss: 0.6769 - accuracy: 0.5804 - 164ms/epoch - 21ms/step\n",
            "Epoch 99/100\n",
            "8/8 - 0s - loss: 0.6799 - accuracy: 0.5804 - 164ms/epoch - 20ms/step\n",
            "Epoch 100/100\n",
            "8/8 - 0s - loss: 0.6801 - accuracy: 0.5804 - 163ms/epoch - 20ms/step\n",
            "1/1 - 0s - loss: 0.5936 - accuracy: 0.8571 - 147ms/epoch - 147ms/step\n",
            "Test accuracy: 0.8571428656578064\n"
          ]
        }
      ]
    }
  ]
}